{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab1: NLTK y Contar Palabras Corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *\n",
    "from nltk import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) _¿Cuál es el número de tokens de Moby Dick?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de tokens de Moby Dick: 218621\n"
     ]
    }
   ],
   "source": [
    "moby_dick_tokens = text1.tokens\n",
    "moby_dick_tokens_nopunct = [word.lower() for word in moby_dick_tokens if re.search(\"\\w\",word)]\n",
    "print(f\"Número de tokens de Moby Dick: {len(moby_dick_tokens_nopunct)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) _¿Cuál es el número de types de Moby Dick?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de types de Moby Dick: 17140\n"
     ]
    }
   ],
   "source": [
    "moby_dick_types = set([word.lower() for word in moby_dick_tokens_nopunct])\n",
    "print(f\"Número de types de Moby Dick: {len(moby_dick_types)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) _Moby Dick type-token ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moby Dick type-token ratio = 0.07840051962071347\n"
     ]
    }
   ],
   "source": [
    "moby_dick_type_token_ratio = len(moby_dick_types) / len(moby_dick_tokens_nopunct)\n",
    "print(f\"Moby Dick type-token ratio = {moby_dick_type_token_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) _Wall Street Journal type-token ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall Street Journal type-token ratio = 0.129748424801388\n"
     ]
    }
   ],
   "source": [
    "wsj_tokens = text7.tokens\n",
    "wsj_tokens_nopunct = [word.lower() for word in wsj_tokens if re.search(\"\\w\",word)]\n",
    "wsj_types = set([word.lower() for word in wsj_tokens_nopunct])\n",
    "wsj_type_token_ratio = len(wsj_types) / len(wsj_tokens_nopunct)\n",
    "print(f\"Wall Street Journal type-token ratio = {wsj_type_token_ratio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5) _¿Cuál de los dos tiene más diversidad léxica?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El que mayor _type-token ratio_ tenga, en este caso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus con mayor diversidad léxica: Wall Street Journal\n"
     ]
    }
   ],
   "source": [
    "mas_diversidad = \"Moby Dick\" if moby_dick_type_token_ratio > wsj_type_token_ratio else \"Wall Street Journal\" \n",
    "print(f\"Corpus con mayor diversidad léxica: {mas_diversidad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6) _¿Puede pensar una razón por la cual ese corpus es más diverso que el otro?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se me ocurre que quizas porque en el Wall Street Journal al ser un corpus de noticias de Wall Street, hay cosas escritas de cualquier tema que va surgiendo, escritas por cualquier persona en muchos contextos distintos.\n",
    "En el de Moby Dick en cambio es una sola persona escribiendo algo sobre un mismo tema, por lo que probablemente se repitan más palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7) _¿Cuál es el Maximum Likelikhood Estimate (MLE) de la palabra \"whale\"(ballena) en Moby Dick?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pmobydick(\"whale\")_ es la cantidad de veces que aparece la palabra \"whale\" en Moby Dick sobre la cantidad total de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pmobydick(\"whale\") = 0.005607878474620462\n"
     ]
    }
   ],
   "source": [
    "mle_whale_moby_dick = moby_dick_tokens_nopunct.count(\"whale\") / len(moby_dick_tokens_nopunct)\n",
    "print(f\"Pmobydick(\\\"whale\\\") = {mle_whale_moby_dick}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8) _¿Cuál es el Maximum Likelikhood Estimate (MLE) de la palabra \"whale\"(ballena) en el Wall Street Journal?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pwsj(\"whale\")_ es la cantidad de veces que aparece la palabra \"whale\" en el Wall Street Journal sobre la cantidad total de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pwsj(\"whale\") = 0.0\n"
     ]
    }
   ],
   "source": [
    "mle_whale_wsj = wsj_tokens_nopunct.count(\"whale\") / len(wsj_tokens_nopunct)\n",
    "print(f\"Pwsj(\\\"whale\\\") = {mle_whale_wsj}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp2020] *",
   "language": "python",
   "name": "conda-env-nlp2020-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
